{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNwithpytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyH-UIViZIJY"
      },
      "source": [
        "#importing libraries\n",
        "import torch \n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O6dujS6aAie"
      },
      "source": [
        "# Defining input size, hidden layer size, output size and batch size respectively\n",
        "n_in, n_h, n_out, batch_size = 10, 5, 1, 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaTlNoUyatRL"
      },
      "source": [
        "# Create dummy input and target tensors (data)\n",
        "x = torch.randn(batch_size, n_in)\n",
        "y = torch.tensor([[1.0], [0.0], [0.0], \n",
        "[1.0], [1.0], [1.0], [0.0], [0.0], [1.0], [1.0]])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lwbCUFkaEhY"
      },
      "source": [
        "# Create a model\n",
        "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
        "   nn.ReLU(),\n",
        "   nn.Linear(n_h, n_out),\n",
        "   nn.Sigmoid())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnC3G8Fwa0-J"
      },
      "source": [
        "#Construct the loss function\n",
        "criterion = torch.nn.MSELoss()\n",
        "# Construct the optimizer (Stochastic Gradient Descent in this case)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXXfHL71a-re",
        "outputId": "2fd2bcf9-0b13-418a-ada0-136d2f2ab4d2"
      },
      "source": [
        "# Gradient Descent\n",
        "for epoch in range(50):\n",
        "   # Forward pass: Compute predicted y by passing x to the model\n",
        "   y_pred = model(x)\n",
        "\n",
        "   # Compute and print loss\n",
        "   loss = criterion(y_pred, y)\n",
        "   print('epoch: ', epoch,' loss: ', loss.item())\n",
        "\n",
        "   # Zero gradients, perform a backward pass, and update the weights.\n",
        "   optimizer.zero_grad()\n",
        "\n",
        "   # perform a backward pass (backpropagation)\n",
        "   loss.backward()\n",
        "\n",
        "   # Update the parameters\n",
        "   optimizer.step()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0  loss:  0.2560594081878662\n",
            "epoch:  1  loss:  0.255850225687027\n",
            "epoch:  2  loss:  0.25564128160476685\n",
            "epoch:  3  loss:  0.255432665348053\n",
            "epoch:  4  loss:  0.2552243173122406\n",
            "epoch:  5  loss:  0.2550162672996521\n",
            "epoch:  6  loss:  0.2548084855079651\n",
            "epoch:  7  loss:  0.25460097193717957\n",
            "epoch:  8  loss:  0.2543937563896179\n",
            "epoch:  9  loss:  0.25418680906295776\n",
            "epoch:  10  loss:  0.2539801001548767\n",
            "epoch:  11  loss:  0.25377365946769714\n",
            "epoch:  12  loss:  0.25356751680374146\n",
            "epoch:  13  loss:  0.25336164236068726\n",
            "epoch:  14  loss:  0.25315600633621216\n",
            "epoch:  15  loss:  0.25295060873031616\n",
            "epoch:  16  loss:  0.25274544954299927\n",
            "epoch:  17  loss:  0.25254058837890625\n",
            "epoch:  18  loss:  0.25233593583106995\n",
            "epoch:  19  loss:  0.25213152170181274\n",
            "epoch:  20  loss:  0.25192737579345703\n",
            "epoch:  21  loss:  0.25172340869903564\n",
            "epoch:  22  loss:  0.25151973962783813\n",
            "epoch:  23  loss:  0.25131627917289734\n",
            "epoch:  24  loss:  0.25111302733421326\n",
            "epoch:  25  loss:  0.2509100139141083\n",
            "epoch:  26  loss:  0.25070720911026\n",
            "epoch:  27  loss:  0.25050464272499084\n",
            "epoch:  28  loss:  0.2503022849559784\n",
            "epoch:  29  loss:  0.25010016560554504\n",
            "epoch:  30  loss:  0.24989823997020721\n",
            "epoch:  31  loss:  0.2496965229511261\n",
            "epoch:  32  loss:  0.2494949847459793\n",
            "epoch:  33  loss:  0.24929368495941162\n",
            "epoch:  34  loss:  0.24909257888793945\n",
            "epoch:  35  loss:  0.2488916665315628\n",
            "epoch:  36  loss:  0.24869093298912048\n",
            "epoch:  37  loss:  0.24849040806293488\n",
            "epoch:  38  loss:  0.24829009175300598\n",
            "epoch:  39  loss:  0.24808993935585022\n",
            "epoch:  40  loss:  0.24788999557495117\n",
            "epoch:  41  loss:  0.24769017100334167\n",
            "epoch:  42  loss:  0.24749059975147247\n",
            "epoch:  43  loss:  0.24729116261005402\n",
            "epoch:  44  loss:  0.24709191918373108\n",
            "epoch:  45  loss:  0.24689283967018127\n",
            "epoch:  46  loss:  0.2466939389705658\n",
            "epoch:  47  loss:  0.24649520218372345\n",
            "epoch:  48  loss:  0.24629661440849304\n",
            "epoch:  49  loss:  0.24609820544719696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leDg4rVNbHWE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}